{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64f40f6",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    brier_score_loss,\n",
    ")\n",
    "import os\n",
    "\n",
    "os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "main_branch = \"Events\"\n",
    "tk_branches = [\n",
    "    \"muon_pixel_tracks_p\",\n",
    "    \"muon_pixel_tracks_pt\",\n",
    "    \"muon_pixel_tracks_ptErr\",\n",
    "    \"muon_pixel_tracks_eta\",\n",
    "    \"muon_pixel_tracks_etaErr\",\n",
    "    \"muon_pixel_tracks_phi\",\n",
    "    \"muon_pixel_tracks_phiErr\",\n",
    "    \"muon_pixel_tracks_chi2\",\n",
    "    \"muon_pixel_tracks_normalizedChi2\",\n",
    "    \"muon_pixel_tracks_nPixelHits\",\n",
    "    \"muon_pixel_tracks_nTrkLays\",\n",
    "    \"muon_pixel_tracks_nFoundHits\",\n",
    "    \"muon_pixel_tracks_nLostHits\",\n",
    "    \"muon_pixel_tracks_dsz\",\n",
    "    \"muon_pixel_tracks_dszErr\",\n",
    "    \"muon_pixel_tracks_dxy\",\n",
    "    \"muon_pixel_tracks_dxyErr\",\n",
    "    \"muon_pixel_tracks_dz\",\n",
    "    \"muon_pixel_tracks_dzErr\",\n",
    "    \"muon_pixel_tracks_qoverp\",\n",
    "    \"muon_pixel_tracks_qoverpErr\",\n",
    "    \"muon_pixel_tracks_lambdaErr\",\n",
    "    \"muon_pixel_tracks_matched\",\n",
    "    \"muon_pixel_tracks_duplicate\",\n",
    "    \"muon_pixel_tracks_tpPdgId\",\n",
    "    \"muon_pixel_tracks_tpPt\",\n",
    "    \"muon_pixel_tracks_tpEta\",\n",
    "    \"muon_pixel_tracks_tpPhi\",\n",
    "]\n",
    "gen_branches = [\n",
    "    \"GenPart_pt\",\n",
    "    \"GenPart_eta\",\n",
    "    \"GenPart_phi\",\n",
    "    \"GenPart_mass\",\n",
    "    \"GenPart_pdgId\",\n",
    "    \"GenPart_statusFlags\",  # added to select last-copy muons\n",
    "]\n",
    "\n",
    "l1tkMuon_branches = [\n",
    "    \"L1TkMu_pt\",\n",
    "    \"L1TkMu_eta\",\n",
    "    \"L1TkMu_phi\",\n",
    "]\n",
    "\n",
    "\n",
    "legacy = False\n",
    "allPixel = False\n",
    "\n",
    "# Configuration Parameters\n",
    "filesSelector = [\n",
    "    \"data/ntuples_TTbarCAExtensionFull.root\",\n",
    "    \"data/ntuples_ZMMCAExtensionFull.root\",\n",
    "    \"data/ntuples_WprimeCAExtensionFull.root\",\n",
    "]\n",
    "\n",
    "filesAllPixel = [\n",
    "    \"data/ntuples_TTbarCAExtensionAllPixel.root\",\n",
    "    \"data/ntuples_ZMMCAExtensionAllPixel.root\",\n",
    "    \"data/ntuples_WprimeCAExtensionAllPixel.root\"\n",
    "]\n",
    "\n",
    "files = filesSelector if not allPixel else filesAllPixel\n",
    "\n",
    "if legacy:\n",
    "    for i, f in enumerate(files):\n",
    "        files[i] = f.replace(\"CAExtension\", \"Legacy\")\n",
    "print(files)\n",
    "\n",
    "# ntuples selection\n",
    "arrays = []\n",
    "for f in files:\n",
    "    with uproot.open(f) as file:\n",
    "        arrays_f = file[main_branch].arrays(tk_branches + gen_branches + l1tkMuon_branches)\n",
    "        arrays = ak.concatenate([arrays, arrays_f], axis=0)\n",
    "    print(f\"Done loading {f}\")\n",
    "\n",
    "print(f\"Loaded {len(arrays)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6040ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "\"\"\"\n",
    "import random\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\"\"\"\n",
    "use_gpu = True\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch version HIP:\", torch.version.hip)\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b0930",
   "metadata": {},
   "source": [
    "## Build Feature Matrix and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4889362",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"muon_pixel_tracks_p\",\n",
    "    \"muon_pixel_tracks_pt\",\n",
    "    \"muon_pixel_tracks_ptErr\",\n",
    "    \"muon_pixel_tracks_eta\",\n",
    "    \"muon_pixel_tracks_etaErr\",\n",
    "    \"muon_pixel_tracks_phi\",\n",
    "    \"muon_pixel_tracks_phiErr\",\n",
    "    \"muon_pixel_tracks_chi2\",\n",
    "    \"muon_pixel_tracks_normalizedChi2\",\n",
    "    \"muon_pixel_tracks_nPixelHits\",\n",
    "    \"muon_pixel_tracks_nTrkLays\",\n",
    "    \"muon_pixel_tracks_nFoundHits\",\n",
    "    \"muon_pixel_tracks_nLostHits\",\n",
    "    \"muon_pixel_tracks_dsz\",\n",
    "    \"muon_pixel_tracks_dszErr\",\n",
    "    \"muon_pixel_tracks_dxy\",\n",
    "    \"muon_pixel_tracks_dxyErr\",\n",
    "    \"muon_pixel_tracks_dz\",\n",
    "    \"muon_pixel_tracks_dzErr\",\n",
    "    \"muon_pixel_tracks_qoverp\",\n",
    "    \"muon_pixel_tracks_qoverpErr\",\n",
    "    \"muon_pixel_tracks_lambdaErr\",\n",
    "]\n",
    "\n",
    "LABEL_FIELD = \"muon_pixel_tracks_matched\"\n",
    "\n",
    "def build_dataset(arr):\n",
    "    mask = arr[features[0]] >= 0\n",
    "    cols = []\n",
    "    for f in features:\n",
    "        minimum = ak.min(ak.flatten(arr[f][mask]))\n",
    "        maximum = ak.max(ak.flatten(arr[f][mask]))\n",
    "        if f in [\"muon_pixel_tracks_p\", \"muon_pixel_tracks_pt\"] or \"Err\" in f:\n",
    "            print(f\"Feature {f} min {minimum:.2f} max {maximum:.2f} -> log10\")\n",
    "            arr[f] = np.log10(arr[f])\n",
    "        flat = ak.to_numpy(ak.flatten(arr[f][mask]))\n",
    "        cols.append(flat)\n",
    "    X = np.vstack(cols).T\n",
    "    y = ak.to_numpy(ak.flatten(arr[LABEL_FIELD][mask])).astype(np.int8)\n",
    "    finite = np.isfinite(X).all(axis=1)\n",
    "    if not finite.all():\n",
    "        X = X[finite]\n",
    "        y = y[finite]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = build_dataset(arrays)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape, \"Positives:\", y.sum(), f\"({100 * y.mean():.2f}%)\")\n",
    "print(\"Feature order:\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b55125",
   "metadata": {},
   "source": [
    "## Train/Test Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe891ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.7  # fraction for train+val\n",
    "val_frac = 0.15   # fraction (of full dataset) reserved for validation (inside train+val)\n",
    "\n",
    "# First split train_val vs test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=train_frac,\n",
    "    stratify=y if (y.sum() > 0 and y.sum() < len(y)) else None,\n",
    ")\n",
    "\n",
    "# Derive actual validation fraction relative to train_val portion\n",
    "if val_frac > 0:\n",
    "    rel_val = val_frac / train_frac  # portion of train_val to carve out as validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        test_size=rel_val,\n",
    "        stratify=y_train_val if (y_train_val.sum() > 0 and y_train_val.sum() < len(y_train_val)) else None,\n",
    "    )\n",
    "else:\n",
    "    X_train, y_train = X_train_val, y_train_val\n",
    "    X_val, y_val = X_test, y_test  \n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Val size:\", X_val.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "# Examine features pre-scaling stats\n",
    "print(\"Pre-scaling feature stats:\")\n",
    "for i in range(X_train.shape[1]):\n",
    "    print(f\"{features[i].split('_')[-1]}: mean={X_train[:, i].mean():.4f}, std={X_train[:, i].std():.4f}\")\n",
    "print(\"--------------------------------------------------------------------\\n Post-scaling feature stats:\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "for i in range(X_train.shape[1]):\n",
    "    print(f\"{features[i].split('_')[-1]}: mean={X_train[:, i].mean():.4f}, std={X_train[:, i].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461dfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "if pos == 0:\n",
    "    pos_weight_value = 1.0\n",
    "else:\n",
    "    pos_weight_value = neg / pos\n",
    "pos_weight = torch.tensor([pos_weight_value], dtype=torch.float32, device=device)\n",
    "print(f\"Class counts train: pos={pos} neg={neg} -> pos_weight={pos_weight_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6a60b",
   "metadata": {},
   "source": [
    "## Torch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "use_weighted_sampler = False\n",
    "\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = NumpyDataset(X_train, y_train)\n",
    "val_ds = NumpyDataset(X_val, y_val)\n",
    "test_ds = NumpyDataset(X_test, y_test)\n",
    "\n",
    "if use_weighted_sampler:\n",
    "    # inverse frequency sampling to upweight minority\n",
    "    class_sample_counts = np.array([ (y_train==0).sum(), (y_train==1).sum() ])\n",
    "    weights = 1.0 / np.clip(class_sample_counts, 1, None)\n",
    "    sample_weights = weights[y_train]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, drop_last=False)\n",
    "else:\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"First batch shapes:\", xb.shape, yb.shape)\n",
    "print(\"Class balance train (orig): pos=\", y_train.sum(), \"neg=\", len(y_train)-y_train.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e9a22",
   "metadata": {},
   "source": [
    "## Define MLP Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, layers, dropout=0):\n",
    "        super().__init__()\n",
    "        seq = []\n",
    "        prev = in_features\n",
    "        for h in layers:\n",
    "            seq.append(nn.Linear(prev, h))\n",
    "            seq.append(nn.BatchNorm1d(h))\n",
    "            seq.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                seq.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        seq.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*seq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "hidden_layers = [512, 128, 64, 32, 16]\n",
    "dropout = 0.3  # slightly higher dropout to regularize\n",
    "lr = 2e-3        # smaller LR for stability\n",
    "weight_decay = 1e-4\n",
    "epochs = 1000\n",
    "patience = 50    # more realistic patience now that we use validation\n",
    "\n",
    "model = MLP(in_features=X.shape[1], layers=hidden_layers, dropout=dropout).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a22322",
   "metadata": {},
   "source": [
    "## Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-metric configuration\n",
    "primary_metric = \"f1\"  # options: 'auc','f1','ap','balanced_accuracy','mcc'\n",
    "optimize_threshold = True\n",
    "threshold_opt_metric = \"f1\"  # which metric to maximize when choosing threshold\n",
    "min_improvement = 1e-4  # required relative improvement for early stopping reset\n",
    "use_focal = True\n",
    "focal_gamma = 2\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, decision_threshold=0.5):\n",
    "    model.eval()\n",
    "    logits_list = []\n",
    "    y_list = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(xb)\n",
    "        logits_list.append(logits.cpu())\n",
    "        y_list.append(yb.cpu())\n",
    "    logits = torch.cat(logits_list).squeeze(1)\n",
    "    y_true = torch.cat(y_list).squeeze(1)\n",
    "    probs = torch.sigmoid(logits).numpy()\n",
    "    y_np = y_true.numpy().astype(int)\n",
    "    preds = (probs >= decision_threshold).astype(int)\n",
    "    cm = confusion_matrix(y_np, preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_np, probs)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    try:\n",
    "        ap = average_precision_score(y_np, probs)\n",
    "    except ValueError:\n",
    "        ap = float(\"nan\")\n",
    "    try:\n",
    "        bal_acc = balanced_accuracy_score(y_np, preds)\n",
    "    except Exception:\n",
    "        bal_acc = float(\"nan\")\n",
    "    try:\n",
    "        f1 = f1_score(y_np, preds, zero_division=0)\n",
    "    except Exception:\n",
    "        f1 = float(\"nan\")\n",
    "    try:\n",
    "        mcc = matthews_corrcoef(y_np, preds)\n",
    "    except Exception:\n",
    "        mcc = float(\"nan\")\n",
    "    return dict(\n",
    "        probs=probs,\n",
    "        y=y_np,\n",
    "        preds=preds,\n",
    "        cm=cm,\n",
    "        auc=auc,\n",
    "        ap=ap,\n",
    "        bal_acc=bal_acc,\n",
    "        f1=f1,\n",
    "        mcc=mcc,\n",
    "    )\n",
    "\n",
    "# Optional Focal Loss wrapper\n",
    "class FocalBCEWithLogits(nn.Module):\n",
    "    def __init__(self, pos_weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(logits)\n",
    "            pt = probs*targets + (1-probs)*(1-targets)\n",
    "        focal_factor = (1-pt)**self.gamma\n",
    "        return (focal_factor * bce_loss).mean()\n",
    "\n",
    "criterion = FocalBCEWithLogits(pos_weight=pos_weight, gamma=focal_gamma) if use_focal else nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "best_metric = -1.0\n",
    "best_state = None\n",
    "best_threshold = 0.5\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item() * xb.size(0)\n",
    "    epoch_loss = running / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate on validation set (use threshold=0.5 first)\n",
    "    val_metrics = evaluate(model, val_loader, device, decision_threshold=0.5)\n",
    "    probs_val = val_metrics[\"probs\"]\n",
    "    y_val = val_metrics[\"y\"]\n",
    "\n",
    "    # Threshold search on validation probabilities\n",
    "    thr_opt = 0.5\n",
    "    if optimize_threshold and probs_val.size > 0:\n",
    "        candidate_thr = np.unique(np.quantile(probs_val, np.linspace(0, 1, 201)))\n",
    "        best_score_local = -1\n",
    "        for t in candidate_thr:\n",
    "            preds_t = (probs_val >= t).astype(int)\n",
    "            if threshold_opt_metric == \"f1\":\n",
    "                metric_t = f1_score(y_val, preds_t, zero_division=0)\n",
    "            elif threshold_opt_metric == \"balanced_accuracy\":\n",
    "                metric_t = balanced_accuracy_score(y_val, preds_t)\n",
    "            elif threshold_opt_metric == \"mcc\":\n",
    "                try:\n",
    "                    metric_t = matthews_corrcoef(y_val, preds_t)\n",
    "                except Exception:\n",
    "                    metric_t = -1\n",
    "            else:\n",
    "                # default to F1\n",
    "                metric_t = f1_score(y_val, preds_t, zero_division=0)\n",
    "            if metric_t > best_score_local:\n",
    "                best_score_local = metric_t\n",
    "                thr_opt = t\n",
    "    if optimize_threshold:\n",
    "        current_threshold = thr_opt\n",
    "    else:\n",
    "        current_threshold = 0.5\n",
    "\n",
    "    # Recompute metrics at chosen threshold\n",
    "    val_metrics_thr = evaluate(model, val_loader, device, decision_threshold=current_threshold)\n",
    "\n",
    "    auc_val = val_metrics_thr[\"auc\"]\n",
    "    ap_val = val_metrics_thr[\"ap\"]\n",
    "    bal_acc_val = val_metrics_thr[\"bal_acc\"]\n",
    "    f1_val = val_metrics_thr[\"f1\"]\n",
    "    mcc_val = val_metrics_thr[\"mcc\"]\n",
    "\n",
    "    metric_map = {\n",
    "        \"auc\": auc_val,\n",
    "        \"f1\": f1_val,\n",
    "        \"ap\": ap_val,\n",
    "        \"balanced_accuracy\": bal_acc_val,\n",
    "        \"mcc\": mcc_val,\n",
    "    }\n",
    "    current_primary = metric_map.get(primary_metric, f1_val)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} loss={epoch_loss:.4f} AUC_val={auc_val:.4f} AP_val={ap_val:.4f} F1_val={f1_val:.4f} BalAcc_val={bal_acc_val:.4f} MCC_val={mcc_val:.4f} thr={current_threshold:.3f} primary({primary_metric})={current_primary:.4f}\"  # noqa: E501\n",
    "    )\n",
    "\n",
    "    if current_primary > best_metric + min_improvement * max(abs(best_metric), 1.0):\n",
    "        best_metric = current_primary\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        best_threshold = current_threshold\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "print(f\"Best {primary_metric}={best_metric:.4f} at threshold={best_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff7cf",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ae046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using best threshold from validation\n",
    "print(f\"Evaluating on test set with threshold={best_threshold:.4f}\")\n",
    "test_metrics = evaluate(model, test_loader, device, decision_threshold=best_threshold)\n",
    "cm = test_metrics[\"cm\"]\n",
    "probs = test_metrics[\"probs\"]\n",
    "y_true = test_metrics[\"y\"]\n",
    "preds = test_metrics[\"preds\"]\n",
    "auc_final = test_metrics[\"auc\"]\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "report = classification_report(y_true, preds, digits=3, zero_division=0)\n",
    "print(report)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true, preds, average=\"binary\", zero_division=0\n",
    ")\n",
    "print(f\"Precision={precision:.3f} Recall={recall:.3f} F1={f1:.3f} AUC={auc_final:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffbbbc",
   "metadata": {},
   "source": [
    "## Extended Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (preds == y_true).mean()\n",
    "precision = (\n",
    "    ((preds & (y_true == 1)).sum() / max((preds == 1).sum(), 1))\n",
    "    if (preds == 1).any()\n",
    "    else 0.0\n",
    ")\n",
    "recall = (preds & (y_true == 1)).sum() / max((y_true == 1).sum(), 1)\n",
    "specificity = ((preds == 0) & (y_true == 0)).sum() / max((y_true == 0).sum(), 1)\n",
    "balanced_accuracy = 0.5 * (recall + specificity)\n",
    "try:\n",
    "    mcc = matthews_corrcoef(y_true, preds)\n",
    "except Exception:\n",
    "    mcc = float(\"nan\")\n",
    "try:\n",
    "    ap = average_precision_score(y_true, probs)\n",
    "except Exception:\n",
    "    ap = float(\"nan\")\n",
    "try:\n",
    "    brier = brier_score_loss(y_true, probs)\n",
    "except Exception:\n",
    "    brier = float(\"nan\")\n",
    "\n",
    "# Precision-Recall threshold analysis\n",
    "prec_curve, rec_curve, thr_pr = precision_recall_curve(y_true, probs)\n",
    "f1_curve = 2 * prec_curve * rec_curve / np.clip(prec_curve + rec_curve, 1e-9, None)\n",
    "max_f1_idx = np.nanargmax(f1_curve)\n",
    "opt_pr_threshold = (\n",
    "    thr_pr[max_f1_idx - 1] if max_f1_idx > 0 and max_f1_idx - 1 < len(thr_pr) else 0.5\n",
    ")\n",
    "best_f1 = f1_curve[max_f1_idx]\n",
    "\n",
    "# Youden J optimal ROC threshold\n",
    "fpr_curve, tpr_curve, thr_roc = roc_curve(y_true, probs)\n",
    "youden = tpr_curve - fpr_curve\n",
    "j_idx = np.argmax(youden)\n",
    "youden_thr = thr_roc[j_idx]\n",
    "\n",
    "print(\"--- Extended Metrics ---\")\n",
    "print(f\"Accuracy            : {acc:.4f}\")\n",
    "print(f\"Precision (0.5 cut) : {precision:.4f}\")\n",
    "print(f\"Recall (TPR)        : {recall:.4f}\")\n",
    "print(f\"Specificity (TNR)   : {specificity:.4f}\")\n",
    "print(f\"Balanced Accuracy   : {balanced_accuracy:.4f}\")\n",
    "print(f\"MCC                 : {mcc:.4f}\")\n",
    "print(f\"Average Precision   : {ap:.4f}\")\n",
    "print(f\"Brier Score         : {brier:.4f}\")\n",
    "print(f\"Best F1             : {best_f1:.4f} at PR threshold ~ {opt_pr_threshold:.4f}\")\n",
    "print(f\"Youden J threshold  : {youden_thr:.4f}\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rec_curve, prec_curve, label=f\"AP={ap:.3f}\")\n",
    "plt.scatter(\n",
    "    rec_curve[max_f1_idx],\n",
    "    prec_curve[max_f1_idx],\n",
    "    marker=\"o\",\n",
    "    color=\"red\",\n",
    "    label=\"Best F1\",\n",
    ")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr_curve, tpr_curve, label=f\"AUC={auc_final:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - DNN\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c835a09",
   "metadata": {},
   "source": [
    "## Probability Distributions Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.hist(probs[y_true == 1], bins=40, histtype=\"step\", label=\"matched\")\n",
    "plt.hist(probs[y_true == 0], bins=40, histtype=\"step\", label=\"fake\")\n",
    "plt.xlabel(\"Predicted Probability (matched)\")\n",
    "plt.ylabel(\"Tracks\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5450b5f",
   "metadata": {},
   "source": [
    "## Confusion Matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed783f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\", cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1821f",
   "metadata": {},
   "source": [
    "## Save Model Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d926e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = {\n",
    "    \"state_dict\": {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "    \"model_config\": {\n",
    "        \"in_features\": X.shape[1],\n",
    "        \"layers\": hidden_layers,\n",
    "        \"dropout\": dropout,\n",
    "    },\n",
    "    \"scaler\": scaler,\n",
    "    \"feature_names\": features,\n",
    "    \"best_threshold\": best_threshold,\n",
    "    \"auc_test\": float(auc_final),\n",
    "}\n",
    "output_artifact = \"dnn_artifact.pt\"\n",
    "torch.save(artifact, output_artifact)\n",
    "size_mb = os.path.getsize(output_artifact) / 1024**2\n",
    "print(f\"Saved artifact to {output_artifact} ({size_mb:.2f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
